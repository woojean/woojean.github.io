---
layout: post
title:  "编写出编译器能够有效优化以转换成高效可执行代码的源代码"
date: 2017-04-06 00:00:01
categories: 计算机系统
tags: 性能 代码优化
excerpt: 代码优化
---

本文是阅读**《深入理解计算机系统》(第5章 优化程序性能)**的一份笔记。

## 编译器的能力和局限性
编译器使用复杂的算法来优化程序，大多数编译器都提供了对优化的控制，比如`gcc -O1`将使用一组基本的优化，而`gcc -O3`则会进行更全面的优化。**更高级别的优化可以进一步提高程序的性能，但是也可能增加程序的规模，并使得程序难以调试**。
编译器必须只使用**安全的**优化，即优化后的程序和未优化的版本应该具有一样的行为。  
```
void func1(int *xp, int *yp){
  *xp += *yp;
  *xp += *yp;
}

void func2(int *xp, int *yp){
  *xp += 2* *yp;
}
```

**func1需要6次存储引用**（2次读*xp、2次读*yp、2次写*xp），而**func2只需要3次存储器引用**（读*xp、读*yp、写*xp），因此func2的效率更高，但是当xp等于yp时，fun1将使xp的值变为原来的4倍，而fun2只会将xp增加为原来的3倍，**因为编译器只进行安全的优化，如果编译器不能确定两个指针是否指向同一个位置，就必须假设什么情况都有可能，所以不会将func1优化为func2的形式**。

再比如：

```
x = 1000;
y = 3000;
*q = y;
*p = x;
v = *q;
```

**v的值依赖于指针p和q是否指向存储器中的同一个位置**，如果不是，v的值等于3000，如果是，则v的值就是1000。

函数调用也可能成为妨碍优化的因素，如：

```
int counter = 0;
int f(){
  return counter ++;
}

int func1(){
  return f() + f() + f() + f(); // 调用4次
}

int func2(){
  return 4*f(); // 只调用1次
}
```

f()函数有一个副作用，即它修改了全局程序状态的一部分，改变它的调用次数会改变程序的行为，因此不能被优化为func2的形式。



## 表示程序性能

使用**CPE** (Cycles Per Element)，来作为度量程序性能的标准。
以计算向量的前置和函数为例，对于长度相同的向量p和a：

```
p[0] = a[0];
p[i] = p[i-1] + a[i]; 

// 函数psum1每次迭代计算一个元素
void psum1(float a[], float p[], long int n){
  long int i;
  p[0] = a[0];
  for(i=1; i<n; i++){
    p[i] = p[i-1] + a[i]; 
  }
}

// 函数psum2使用循环展开的技术，每次迭代计算两个元素，以此减少迭代的次数
void psum2(float a[], float p[], long int n){
  long int i;
  p[0] = a[0];
  
  // 使用循环展开技术，每次对p[i]和p[i+1]共两个值进行赋值
  for(i=1; i<n-1; i+=2){
    float mid_val = p[i-1] + a[i];
    p[i] = mid_val; 
    p[i+1] = mid_val + a[i+1];
  }

  if(i<n){
    p[i] = p[i-1] + a[i]; 
  }
}
```
psum1和psum2的运行时间（以时钟周期为单位）分别近似于496+10.0n和500+6.5n（使用最小二乘法拟合方法得到），**对于较大的n值，运行时间就会主要由n来决定**，其中n的系数（10.0和6.5）就称为`CPE有效数`。以CPE为度量标准，psum2的CPE为6.5，优于CPE为10.0的psum1。



## 程序示例

```
#define IDENT 0
#define OP +

typedef int data_t;

typedef struct{
  long int len;
  data_t *data;
} vec_rec,*vec_ptr;

vec_ptr new_vec(long int len){
  vec_ptr result = (vec_ptr)malloc(sizeof(vec_rec));
  if(!result){
    return NULL;
  }
  result->len = len;
  if(len>0){
    data_t *data = (data_t *)calloc(len, sizeof(data_t));
      if(!data){
        free((void *) result);
        return NULL;
      }
      result->data = data;
  }
  else{
    result->data = NULL;
  }
  return result;
}

// 将向量中索引为index的元素赋值到dest位置，成功返回1，失败返回0
int get_vec_element(vec_ptr v,long int index,data_t *dest){
  if(index<0 || index>=v->len){
    return 0;
  }
  *dest = v->data[index];
  return 1;
}

long int vec_length(vec_ptr v){
  return v->len;
}

// 向量合并运算的初步实现
void combine1(vec_ptr v,data_t *dest){
  long int i;

  *dest = IDENT;
  for(i = 0; i < vec_length(v); i++){
    data_t val;
    get_vec_element(v,i,&val);
    *dest = *dest OP val;
  }
}
```

combine1函数的CPE如下：
```
             +         *         +        F*         D*
未优化     20.02     29.21     27.40     27.90     27.36
-O1优化    12.00     12.00     12.00     12.01     13.00
```



## 消除循环的低效率

```
void combine2(vec_ptr v,data_t *dest){
  long int i;
  
  // 将计算向量长度的运算从循环中移出
  long int length = vec_length(v); 

  *dest = IDENT;
  for(i = 0; i < length; i++){
    data_t val;
    get_vec_element(v,i,&val);
    *dest = *dest OP val;
  }
}
```
combine2函数的CPE如下：
```
             +         *         +        F*         D*
-O1优化    12.00     12.00     12.00     12.01     13.00
combine2    8.03      8.09     10.09     11.09     12.08
```



## 减少过程调用

过程调用会带来相当大的开销，而且妨碍大多数形式的程序优化。
```
data_t *get_vec_start(vec_ptr v){
  return v->data;
}

void combine3(vec_ptr v,data_t *dest){
  long int i;
  long int length = vec_length(v);
  
  // 将过程调用从循环中移出
  data_t *data = get_vec_start(v); 

  *dest = IDENT;
  for(i = 0; i < length; i++){
    *dest = *dest OP data[i];
  }
}
```

```
             +         *         +        F*         D*
combine2    8.03      8.09     10.09     11.09     12.08
combine3    6.01      8.01     10.01     11.01     12.02
```



## 消除不必要的存储器引用

combine3中将合并运算计算的值累积在指针dest中，在第i次迭代中，程序读出这个位置处的值，计算后再将其存回到dest，**这样的读写很浪费，因为每次迭代开始时从dest中读出的值就是上次迭代最后写入的值**。
```
void combine4(vec_ptr v,data_t *dest){
  long int i;
  long int length = vec_length(v);
  data_t *data = get_vec_start(v); 
  
  // 在临时变量中存放结果
  data_t acc =IDENT; 

  for(i = 0; i < length; i++){
    acc = acc OP data[i];
  }
  *dest = acc;
}
```

```
             +         *         +        F*         D*
combine3    6.01      8.01     10.01     11.01     12.02
combine4    2.00      3.00      3.00      4.00      5.00
```



## 理解现代处理器*

典型的现代处理器可以在每个时钟周期执行多个操作，而且是`乱序`的，可以达到更高的`指令级并行`（基于指令高速缓存、分支预测等实现）。
详略。



## 循环展开

**循环展开通过增加每次迭代计算的元素的数量，减少循环的迭代次数。**
对于整数加法和乘法，循环展开使CPE有所改进，但是对于浮点数运算却没有，即**循环展开不能改进浮点数运算**（与CPU进行浮点数计算的方式有关）。
```
void combine5(vec_ptr v,data_t *dest){
  long int i;
  long int length = vec_length(v);
  long int limit = length - 1;
  data_t *data = get_vec_start(v); 
  data_t acc =IDENT;

  // 循环展开2次
  for(i = 0; i < limit; i+=2){
    acc = (acc OP data[i]) OP data[i+1];
  }

  for(; i<length; i++){
    acc = acc OP data[i];
  }

  *dest = acc;
}
```
```
             +         *         +        F*         D*
combine4    2.00      3.00      3.00      4.00      5.00
combine5    2.00      1.50      3.00      4.00      5.00
```

编译器可以很容易地执行循环展开，如gcc可以使用`-funroll-loops`选项来执行循环展开。



## 提高并行性

```
void combine6(vec_ptr v,data_t *dest){
  long int i;
  long int length = vec_length(v);
  long int limit = length - 1;
  data_t *data = get_vec_start(v); 
  data_t acc0 =IDENT;
  data_t acc1 =IDENT;

  // 循环展开2次，并且使用2路并行（因而有两条关键路径）
  for(i = 0; i < limit; i+=2){
    acc0 = acc0 OP data[i];
    acc1 = acc1 OP data[i+1];
  }

  for(; i<length; i++){
    acc0 = acc0 OP data[i];
  }

  *dest = acc0 OP acc1;
}
```
```
             +         *         +        F*         D*
combine5    2.00      1.50      3.00      4.00      5.00
combine6    1.50      1.50      1.50      2.00      2.50
```

编译器能够将combine4中的代码转换为combine5中的二路循环展开变种，再引入并行性，将其转换成combine6的一个变种。

改变内循环中元素合并的方式：
```
void combine7(vec_ptr v,data_t *dest){
  long int i;
  long int length = vec_length(v);
  long int limit = length - 1;
  data_t *data = get_vec_start(v); 
  data_t acc =IDENT;

  // 循环展开2次
  for(i = 0; i < limit; i+=2){
    // 重新结合变换
    acc = acc OP (data[i] OP data[i+1]);  
  }

  for(; i<length; i++){
    acc = acc OP data[i];
  }

  *dest = acc;
}
```
```
             +         *         +        F*         D*
combine6    1.50      1.50      1.50      2.00      2.50
combine7    2.00      1.51      1.50      2.00      2.97
```
可以看到该优化对浮点数的计算也是有效的。
**重新结合变换能够减少计算中关键路径上的操作的数量，通过更好地利用CPU功能单元的流水线能力得到更好的性能**。

如果对循环展开多次，同时使用多路并行，可以使CPE趋近于1：
```
                     +         *         +        F*         D*
展开5次，5路并行    1.01      1.00      1.00      1.00      1.00
```

能够利用GCC对SIMD（单指令多数据）向量指令的支持更进一步地提高性能，对于整数和单精度数据，`处理器可以支持每个周期4个合并操作`，而对于双精度数据，每个周期2个。
```
                +         *         +        F*         D*
SIMD+8次展开   0.25      0.50      0.25      0.25      0.50
```



## 限制因素

在一个程序的数据流图表示中，**关键路径**指明了该程序所需时间的一个基本下界，即如果程序中有某条数据相关链，这条链上所有延迟之和等于T，那么这个程序至少需要T个周期才能执行完。

功能单元的吞吐量界限也是程序执行时间的一个下界，即如果一个程序一共需要N个某种运算的计算，而微处理器只有m个能执行这个操作的功能单元，并且这些单元的发射时间为i，那么这个程序的执行时间至少需要N*i/m个周期。

如果并行度超过了可用的寄存器的数量，那么编译器会使用**寄存器溢出**，即把某些临时值存放到栈中，在这种情况下性能会急剧下降。

当分支预测逻辑不能正确预测一个分支是否需要跳转的时候，条件分支可能会导致严重的**预测错误处罚**。处理器的工作超前于正在执行的指令，如果指令遵循的是一种简单的顺序，那么这种指令流水线化就能很好地工作，当遇到分支的时候，处理器必须猜测分支该往哪个方向走。对于`条件转移`的情况，这意味着要预测是否会选择分支，对于`间接跳转`或`过程返回`这样的指令，这意味着预测目标地址。
如果预测是正确的，那么处理器就会提交投机执行的指令的结果，把它们存储到寄存器或存储器中，如果预测结果是错误的，处理器必须丢弃掉所有投机执行的结果，在正确的位置重新开始取指令的过程。对于i7来说，预测错误处罚是44个时钟周期。

最新的x86处理器有条件传送指令，在编译条件语句和表达式时，gcc能够产生使用这些指令的代码，而不是更传统的基于控制的条件转移的实现。翻译成条件传送的基本思想是计算出一个条件表达式或语句两个方向上的值，然后用条件传送选择期望的值。`条件传送指令可以被实现为普通指令流水线化处理的一部分，没有必要猜测条件是否满足，因此猜测错误也没有处罚`。

现代处理器中的分支预测逻辑非常善于辨别不同的分支指令有规律的模式和长期的趋势，因此不要过分关心可预测的分支。对于无法预测的情况，如果编译器能够产生使用条件数据传送而不是使用条件控制转移的代码，可以极大地提高程序的性能，这不是C语言程序可以直接控制的，但是有些表达条件行为的方法能够更直接地被翻译成条件传送，而不是其他操作。如下两个函数实现同样的功能：将a[i]设置为a[i]和b[i]中较小的那一个，将b[i]设置为较大的那一个。
```
void minmax1(int a[], int b[], int n){
  int i;
  for(i=0; i<n; i++){
    if(a[i] > b[i]){
      int t =  a[i];
      a[i] = b[i];
      b[i] = t;
    }
  }
}

void minmax2(int a[], int b[], int n){
  int i;
  for(i=0; i<n; i++){
    if(a[i] > b[i]){
      int min = a[i] < b[i] ? a[i] : b[i];
      int max = a[i] < b[i] ? b[i] : a[i];
      a[i] = min;
      b[i] = max;
    }
  }
}
```
使用随机数据测试minmax1，CPE大约为14.50，使用可预测的数据，CPE大约为3.00~4.00。
对于minmax2，无论哪种类型的数据，CPE大约都为5.0



## 理解存储器性能

现代处理器有专门的功能单元来执行加载和存储操作，这些单元有内部的缓冲区来保存未完成的存储器操作请求集合，例如i7的`加载单元`的缓冲区可以保存最多48个读请求，而`存储单元`的缓冲区可以保存最多32个写请求。每个这样的单元通常可以每个时钟周期开始一个操作。

合并运算的测试表明，当不使用SIMD时CPE从没有低于1.00，其中一个制约因素是：对于每一个被计算的元素，都需要从存储器中读一个值，由于加载单元每个时钟周期只能启动一条加载操作，所以CPE不可能低于1.00。对于每个被计算的元素必须加载k个值的应用，不可能获得低于k的CPE。

在大多数情况下存储操作与加载操作一样，能够在完全流水线化的模式中工作，每个周期开始一条新的存储。但是与加载操作不同的是，存储操作并不影响任何寄存器值，因此通常一系列存储操作不会产生数据关联，但是当加载操作是受存储操作的结果影响时会有一些问题。如下函数：
```
void write_read(int *src, int *dest, int n){
  int cnt = n;
  int val = 0;
  while(cnt--){
    *dest = val;
    val = (*src)+1;
  }
}
```
a的值为[-10,17];
当执行write_read(&a[0],&a[1],3)时，指针引用*src的每次加载都会得到值-10，因此在两次迭代之后，数组的元素就会分别保持固定的-10和-9.从src读出的结果不受对dest写的影响，测试得到这种情况下的CPE为2.00
当执行write_read(&a[0],&a[0],3)时，*src的每次加载都会得到*dest的前次执行存储的值，因而一系列不断增加的值会被存储在这个位置，这就产生了`写读相关`：一个存储器读的结果依赖于一个最近的存储器写，性能测试发现CPE为6.00
写读相关现象产生性能差异的本质在于加载、存储单元的执行方式。存储单元包含一个存储缓冲区，它包含已经被发射到存储单元但还没有完成的存储操作的地址和数据，这里的完成包括更新数据高速缓存。提供这样一个缓冲区使得一系列存储操作不必等待每个操作都更新高速缓存就能够执行。当一条加载操作发生时，它必须检查存储缓冲区中的条目，如果有地址相匹配，它就取出相应的数据条目作为加载操作的结果。当存在写读相关时，读操作必须等写操作将其结果放到存储缓冲区中后才能执行，而如果没有写读相关，则两个操作可以独立地进行。
对于寄存器操作，在指令被译码成操作的时候，处理器就可以确定哪些指令会影响其他哪些指令。对于存储器操作，只有计算出加载和存储的地址被计算出来以后，处理器才能确定哪些指令会影响其他的哪些。
